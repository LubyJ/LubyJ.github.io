{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f4d1fc",
   "metadata": {},
   "source": [
    "# Decision Tree 학습모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d80c38",
   "metadata": {},
   "source": [
    "<img src='https://user-images.githubusercontent.com/127171630/226094024-8fe71023-3196-43b6-b982-170a121ebdad.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407083ac",
   "metadata": {},
   "source": [
    "* Decision Tree 모델은 __분류__ 와 __회귀__ 모두 가능한 __지도학습__ 모델\n",
    "* 변수 X를 넣어주면 모델이 알아서 조건과 결과값을 학습함.\n",
    "* 위 모델은 Root Node(첫 번째 분류 기준)로부터 질문에 대한 Y/N에 따라 가지를 뻗쳐나감.\n",
    "* __Root Node__ 다음부터 나오는 분류기준은 __Decision Node__ , 그에 따른 최종 결과값은 __Leaf Node__ 라고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674e292",
   "metadata": {},
   "source": [
    "## <font color=red>장점</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba3ad7",
   "metadata": {},
   "source": [
    "1. 전처리 과정이 복잡하지 않음\n",
    "2. multi-output을 갖는 데이터를 핸들링하기에 용이\n",
    "3. 결과 해석이 용이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee7055",
   "metadata": {},
   "source": [
    "## <font color=red>단점</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5d72c",
   "metadata": {},
   "source": [
    "1. max_depth가 너무 크면 과적합(overfitting) 문제 발생\n",
    "2. max_depth가 너무 작으면 과소적합 문제 발생\n",
    "3. 아주 작은 variation으로도 불안정해질 수 있음\n",
    "4. 특정 class 가 dominant 하다면 편향 문제 발생\n",
    "5. 변수들이 independent하지 않은 경우 multi-output 문제 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f584cd2",
   "metadata": {},
   "source": [
    "## <font color=red>학습 메커니즘</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6975219",
   "metadata": {},
   "source": [
    "__불순도(impurity)__ 는 해당 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지를 나타냄\n",
    "__엔트로피(Entropy)__ 는 불순도를 수치로 나타낸 것 (__엔트로피가 높다 = 불순도가 높다__)\n",
    "\n",
    "해당 모델은 불순도를 최소화 하는 방법으로 학습된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29cf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Decision Tree 학습 모델 로드\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe00c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 모듈 로드\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_classifier(y_test, y_pred, roc = False):\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred): .4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average = 'macro'): .4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average = 'macro'): .4f}\")\n",
    "    print(f\"F_SCORE: {f1_score(y_test, y_pred, average = 'macro'): .4f}\")\n",
    "    if roc:\n",
    "        print(f\"ROC_AUC: {roc_auc_score(y_test, y_pred, average = 'macro', multi_class = 'ovr'): .4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63637635",
   "metadata": {},
   "source": [
    "## 데이터셋_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be56d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits() \n",
    "digits_data = digits.data\n",
    "digits_label = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234c7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe95107",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eafe7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5639\n",
      "Precision:  0.5733\n",
      "Recall:  0.5828\n",
      "F_SCORE:  0.5276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92        31\n",
      "           1       0.35      0.18      0.24        38\n",
      "           2       0.00      0.00      0.00        38\n",
      "           3       0.18      0.89      0.30        27\n",
      "           4       0.70      0.93      0.80        41\n",
      "           5       0.91      0.89      0.90        35\n",
      "           6       0.89      0.84      0.86        38\n",
      "           7       0.76      0.94      0.84        34\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       1.00      0.26      0.41        43\n",
      "\n",
      "    accuracy                           0.56       360\n",
      "   macro avg       0.57      0.58      0.53       360\n",
      "weighted avg       0.59      0.56      0.53       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SJang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred1 = decision_tree.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67c1da",
   "metadata": {},
   "source": [
    "* 전체적인 평가지표 수치가 많이 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3329008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0,  2,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  7,  0, 20,  8,  0,  0,  3,  0,  0],\n",
       "       [ 0, 10,  0, 22,  0,  0,  4,  2,  0,  0],\n",
       "       [ 0,  2,  0, 24,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0, 38,  1,  0,  2,  0,  0],\n",
       "       [ 1,  0,  1,  0,  1, 31,  0,  1,  0,  0],\n",
       "       [ 0,  1,  0,  1,  3,  1, 32,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  1,  0,  0, 32,  0,  0],\n",
       "       [ 1,  0,  0, 32,  0,  1,  0,  1,  0,  0],\n",
       "       [ 0,  0,  1, 29,  2,  0,  0,  0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adaf82",
   "metadata": {},
   "source": [
    "* max_depth를 줄이니 leaf node가 네번째에 생성이 됨. 이때, max_depth=default (가지수 12) 로 했을 때 보다 뻗어나간 가지개수가 현저히 적기 때문에 분류가 잘 수행되지 않은 것으로 보임.\n",
    "* max_depth를 30으로 늘려보면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa80159",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth=30, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43fee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8444\n",
      "Precision:  0.8482\n",
      "Recall:  0.8451\n",
      "F_SCORE:  0.8450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        31\n",
      "           1       0.84      0.82      0.83        38\n",
      "           2       0.73      0.87      0.80        38\n",
      "           3       0.71      0.74      0.73        27\n",
      "           4       0.94      0.80      0.87        41\n",
      "           5       0.87      0.94      0.90        35\n",
      "           6       0.87      0.89      0.88        38\n",
      "           7       0.91      0.94      0.93        34\n",
      "           8       0.79      0.77      0.78        35\n",
      "           9       0.80      0.77      0.79        43\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.85      0.84       360\n",
      "weighted avg       0.85      0.84      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred2 = decision_tree.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a7261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  1,  0,  0,  0,  0,  0,  2,  0],\n",
       "       [ 0, 31,  2,  2,  1,  0,  1,  0,  1,  0],\n",
       "       [ 0,  0, 33,  1,  0,  1,  0,  0,  2,  1],\n",
       "       [ 0,  1,  1, 20,  0,  1,  1,  0,  1,  2],\n",
       "       [ 0,  0,  0,  1, 33,  0,  3,  2,  0,  2],\n",
       "       [ 0,  0,  1,  0,  0, 33,  0,  1,  0,  0],\n",
       "       [ 0,  1,  2,  0,  1,  0, 34,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0, 32,  0,  1],\n",
       "       [ 0,  1,  3,  1,  0,  1,  0,  0, 27,  2],\n",
       "       [ 0,  3,  2,  2,  0,  2,  0,  0,  1, 33]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cff566",
   "metadata": {},
   "source": [
    "* Max_depth를 2배 이상 높였을 때 평가지표가 전체적으로 아주 미미하게 향상된 것으로 보아 이미 default로 돌린 max_depth이후로는 분류성능이 saturation된 듯 하다.\n",
    "* 분류 기준을 default인 gini에서 entropy로 바꿔보면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df12788",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion='entropy', max_depth=30, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d8d56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8444\n",
      "Precision:  0.8472\n",
      "Recall:  0.8432\n",
      "F_SCORE:  0.8440\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93        31\n",
      "           1       0.86      0.79      0.82        38\n",
      "           2       0.87      0.89      0.88        38\n",
      "           3       0.81      0.78      0.79        27\n",
      "           4       0.89      0.80      0.85        41\n",
      "           5       0.81      0.83      0.82        35\n",
      "           6       0.92      0.92      0.92        38\n",
      "           7       0.80      0.82      0.81        34\n",
      "           8       0.69      0.83      0.75        35\n",
      "           9       0.86      0.86      0.86        43\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.84      0.84       360\n",
      "weighted avg       0.85      0.84      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred3 = decision_tree.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "346bf816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0,  0,  1,  0,  1,  0,  1,  0],\n",
       "       [ 0, 30,  0,  0,  0,  1,  0,  2,  3,  2],\n",
       "       [ 0,  1, 34,  1,  0,  1,  0,  0,  1,  0],\n",
       "       [ 0,  1,  0, 21,  0,  0,  0,  0,  3,  2],\n",
       "       [ 0,  1,  0,  0, 33,  1,  0,  3,  3,  0],\n",
       "       [ 0,  0,  1,  1,  1, 29,  2,  1,  0,  0],\n",
       "       [ 1,  0,  1,  0,  0,  1, 35,  0,  0,  0],\n",
       "       [ 0,  0,  2,  3,  0,  1,  0, 28,  0,  0],\n",
       "       [ 0,  1,  1,  0,  2,  0,  0,  0, 29,  2],\n",
       "       [ 0,  1,  0,  0,  0,  2,  0,  1,  2, 37]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8075964e",
   "metadata": {},
   "source": [
    "* 분류기준을 gini impurity에서 entropy로 바꿔도 큰 차이가 없음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0dacc",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eca846",
   "metadata": {},
   "source": [
    "* 의사결정 모델은(random forest 포함) impurity(혹은 entropy)가 0이 될 경우, 즉, 분류한 클래스에 다른 클래스의 요소가 포함되어있지 않다고 판단되면 학습은 끝이난다.\n",
    "<br>\n",
    "<br>\n",
    "* 궁금증\n",
    "    * 의사결정 모델이 digits 분류를 잘 못하는 이유는 뭘까.\n",
    "        1. 특정 클래스가 dominant해서 편향된 것은 아님 (데이터 10개 차이남)\n",
    "        2. max_depth가 작아서 과소적합이 일어난것도 아님. 이미 saturation됨을 위에서 확인.\n",
    "        3. training data수가 부족했거나, 분류해야 할 클래스 개수가 너무 많아서?\n",
    "        4. 단순히 해당 모델이 적합하지 않아서? 그렇다면 왜 적합하지 않은건지?\n",
    "    * 하나의 데이터셋으로 여러가지 모델을 학습시킨 후, 단순히 평가지표 수치가 높으면 적합한 모델, 그렇지 찮으면 부적합한 모델이라 여기고 넘어가는게 모델을 학습하고 평가할 때 일반적인 과정인가?\n",
    "    * 왜 해당 모델이 적합하고, 적합하지 않은지 분석하는 방법이 있나?\n",
    "    * 이미지 데이터를 보면 분류하기 어려울만 하게 생겼는데, 이미지를 전처리 하는 방식은 뭐가 있는지?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
