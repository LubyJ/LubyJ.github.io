{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64889da8",
   "metadata": {},
   "source": [
    "* 한국어 데이터셋 이용\n",
    "* GLUE benchmark의 한국어 버전 [KLUE benchmark](), GLUE와 마찬가지로 한국어 자연어처리에 대한 이해도를 높이기 위해 만들어진 데이터셋 benchmark\n",
    "* KLUE의 dataset을 활용하는 것이 아닌, model(klue/ber-base)를 활용하여 NSMC(Naver Sentiment Movie Corpus) task를 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5083510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import transformers\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927d833",
   "metadata": {},
   "source": [
    "### STEP 1. NSMC 데이터 분석 및 Huggingface dataset 구성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda488e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b92dd11508545a5a2cb5cb91c511cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743af813b066429eb738a7c5fe3df973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/807 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nsmc/default (download: 18.62 MiB, generated: 20.90 MiB, post-processed: Unknown size, total: 39.52 MiB) to /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcb4c3600bc48fe8e8fd695bc14a5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce1b878ef704a7aafb73ecb14e12b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/6.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398824ac43864e4896fe2171f2d13889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3260503835e42738a1f3e945871c32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nsmc downloaded and prepared to /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n",
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    }
   ],
   "source": [
    "val_nsmc = load_dataset('nsmc', split='train[:50000]')\n",
    "train_nsmc = load_dataset('nsmc', split='train[50000:]')\n",
    "test_nsmc = load_dataset('nsmc', split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7b8f5",
   "metadata": {},
   "source": [
    "### STEP 2. klue/bert-base model 및 tokenizer 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8bdb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4810712c1c42cd855dd02f08fc2884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4641b1f7358412a9f2d6fd9c4f065e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/260M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7629a82084464c9cb8967ec6ed4891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981086dd3f1545748b7ede3753f8d44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc7e73ef60440b49a1d79301e783d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b56f63aaac4c059aa9d82bf0de45f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/roberta-small\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ae01d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['재미',\n",
       " '##가',\n",
       " '없',\n",
       " '##으면',\n",
       " '길',\n",
       " '##게',\n",
       " '##만',\n",
       " '##들',\n",
       " '##지도',\n",
       " '마',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '샬',\n",
       " '##리',\n",
       " '##즈',\n",
       " '##테',\n",
       " '##론',\n",
       " '내내',\n",
       " '##버',\n",
       " '##럭',\n",
       " '##하고',\n",
       " '틴',\n",
       " '##에이',\n",
       " '##저',\n",
       " '##퀸',\n",
       " '스튜어트',\n",
       " '##는',\n",
       " '앞',\n",
       " '##니',\n",
       " '##만',\n",
       " '##보이',\n",
       " '##고',\n",
       " '몰입',\n",
       " '##감',\n",
       " '##도',\n",
       " '없',\n",
       " '##고',\n",
       " '토르',\n",
       " '##는',\n",
       " '내내',\n",
       " '지저분',\n",
       " '##해서',\n",
       " '정도',\n",
       " '안',\n",
       " '##가',\n",
       " '##는데',\n",
       " '김보',\n",
       " '##성',\n",
       " '##느',\n",
       " '##낌',\n",
       " '##나',\n",
       " '##고',\n",
       " '애매',\n",
       " '##한',\n",
       " '캐릭터',\n",
       " '윌리엄',\n",
       " '##에',\n",
       " '무의미',\n",
       " '##한',\n",
       " '전투',\n",
       " '##씬',\n",
       " '##들',\n",
       " '.',\n",
       " '.',\n",
       " '억지로',\n",
       " '끼워',\n",
       " '##넣',\n",
       " '##은',\n",
       " '난장',\n",
       " '##이',\n",
       " '##들',\n",
       " '.',\n",
       " '대체',\n",
       " '뭘',\n",
       " '##위',\n",
       " '##해서',\n",
       " '?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(train_nsmc['document'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbbc48",
   "metadata": {},
   "source": [
    "### STEP 3. 위에서 불러온 tokenizer으로 데이터셋 전처리 및 model 학습 \n",
    "\n",
    "### STEP 4. Fine-tuning을 통해 모델 성능(accuracy) 향상시키기\n",
    "- 모델과 토크나이저를 klue/bert-base'에서 'klue/roberta-small'로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e309fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation = True,\n",
    "        padding = 'max_length',\n",
    "        return_token_type_ids = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cd052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59899e06250f469988d65724e5bfa3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7d870d6b4d4fbd8e00f90d9328e1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2c410aab1f497c80caf9a94309ec9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_nsmc.map(transform, batched=True)\n",
    "val_dataset = val_nsmc.map(transform, batched=True)\n",
    "test_dataset = test_nsmc.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e732e",
   "metadata": {},
   "source": [
    "hf_dataset = huggingface_nsmc_dataset.map(transform, batched=True)\n",
    "\n",
    "hf_train_dataset = hf_dataset['train']\n",
    "#hf_val_dataset = hf_dataset['validation']\n",
    "hf_test_dataset = hf_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da417613",
   "metadata": {},
   "source": [
    "__Trainer를 활용한 학습__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658702e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,                                         # output이 저장될 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 16,   # 각 device 당 batch size\n",
    "    per_device_eval_batch_size = 16,    # evaluation 시에 batch size\n",
    "    num_train_epochs = 3,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.01,                        # weight decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096ab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "#metric = load_metric('glue', 'mrpc')\n",
    "\n",
    "#def compute_metrics(eval_pred):    \n",
    "#    predictions,labels = eval_pred\n",
    "#    predictions = np.argmax(predictions, axis=1)\n",
    "#    return metric.compute(predictions=predictions, references = labels)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    m1 = load_metric('accuracy')\n",
    "    m2 = load_metric('f1')\n",
    "\n",
    "    acc = m1.compute(predictions=preds, references=labels)['accuracy']\n",
    "    f1 = m2.compute(predictions=preds, references=labels)['f1']\n",
    "\n",
    "    return {'accuracy':acc, 'f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07660bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 100000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 4:45:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.267173</td>\n",
       "      <td>0.893180</td>\n",
       "      <td>0.891679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.275799</td>\n",
       "      <td>0.895800</td>\n",
       "      <td>0.898043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.347173</td>\n",
       "      <td>0.900480</td>\n",
       "      <td>0.900979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-6000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547408775cda46d0b179944508d0e120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13b5cdc029b4100bb487645fedac8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-12500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-17500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=0.23769442647298178, metrics={'train_runtime': 17116.5177, 'train_samples_per_second': 17.527, 'train_steps_per_second': 1.095, 'total_flos': 3.97402195968e+16, 'train_loss': 0.23769442647298178, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset=train_dataset,    # training dataset\n",
    "    eval_dataset=val_dataset,       # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03017bd8",
   "metadata": {},
   "source": [
    "* Accuracy와 F1이 약 90%에 도달함"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "939dc650",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a332279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 13:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaad27e5b0b4adfa882588adaa9d187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33165a1aef142b5b776680f1672bb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3624119460582733, 'eval_accuracy': 0.89664, 'eval_f1': 0.8975700638205097, 'eval_runtime': 831.7183, 'eval_samples_per_second': 60.117, 'eval_steps_per_second': 3.757}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "chck_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/checkpoint-18500'\n",
    "save_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/checkpoint-18500/eval'\n",
    "\n",
    "# Load the saved checkpoints\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chck_dir)\n",
    "\n",
    "# Create a new Trainer instance for evaluation\n",
    "evaluation_args = TrainingArguments(\n",
    "    output_dir=save_dir,               # Same output directory as during training\n",
    "    per_device_eval_batch_size=16,       # Evaluation batch size\n",
    ")\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=evaluation_args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test_dataset\n",
    "eval_result = eval_trainer.evaluate(test_dataset)\n",
    "\n",
    "# Print the evaluation result\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3663c52",
   "metadata": {},
   "source": [
    "학습시 저장된 checkpoint를 불러와서 test_dataset 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e66d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-small\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 13:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36268582940101624, 'eval_accuracy': 0.8959, 'eval_f1': 0.897456608680234, 'eval_runtime': 837.598, 'eval_samples_per_second': 59.695, 'eval_steps_per_second': 3.731}\n"
     ]
    }
   ],
   "source": [
    "chck_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/checkpoint-18000'\n",
    "save_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/checkpoint-18000/eval'\n",
    "\n",
    "# Load the saved checkpoints\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chck_dir)\n",
    "\n",
    "# Create a new Trainer instance for evaluation\n",
    "evaluation_args = TrainingArguments(\n",
    "    output_dir=save_dir,               # Same output directory as during training\n",
    "    per_device_eval_batch_size=16,       # Evaluation batch size\n",
    ")\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=evaluation_args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test_dataset\n",
    "eval_result = eval_trainer.evaluate(test_dataset)\n",
    "\n",
    "# Print the evaluation result\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58864be",
   "metadata": {},
   "source": [
    "### STEP 5. Bucketing을 적용하여 학습시키고, STEP 4의 결과와의 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969ab758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 100000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 4:42:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.546226</td>\n",
       "      <td>0.887940</td>\n",
       "      <td>0.890329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.508087</td>\n",
       "      <td>0.891680</td>\n",
       "      <td>0.893310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.585833</td>\n",
       "      <td>0.894700</td>\n",
       "      <td>0.895455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-6000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-12500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-17500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=0.0984495556640625, metrics={'train_runtime': 16965.7088, 'train_samples_per_second': 17.683, 'train_steps_per_second': 1.105, 'total_flos': 3.97402195968e+16, 'train_loss': 0.0984495556640625, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/Bucketing'\n",
    "\n",
    "\"\"\"custom bucket_batch_size를 지정하고 싶으면 아래와 같이 쓰면 됨\"\"\"\n",
    "# bucket_batch_sizes = [8, 16, 32]\n",
    "# bucket_batch_sizes=bucket_batch_sizes in 'training_args = TrainingArguments()'\n",
    "\n",
    "# Define the TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True,  # Enable grouping by sequence length\n",
    "    dataloader_num_workers=4,\n",
    ")\n",
    "\n",
    "# Create a DataCollator\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49bda216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/aiffel/aiffel/[GN08]_HuggingFace/checkpoint-18000\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /aiffel/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 13:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6123278737068176, 'eval_accuracy': 0.89036, 'eval_f1': 0.8915357524435122, 'eval_runtime': 837.003, 'eval_samples_per_second': 59.737, 'eval_steps_per_second': 3.734}\n"
     ]
    }
   ],
   "source": [
    "chck_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500'\n",
    "save_dir = os.getenv('HOME')+'/aiffel/[GN08]_HuggingFace/Bucketing/checkpoint-18500/eval'\n",
    "\n",
    "# Load the saved checkpoints\n",
    "model = AutoModelForSequenceClassification.from_pretrained(chck_dir)\n",
    "\n",
    "# Create a new Trainer instance for evaluation\n",
    "evaluation_args = TrainingArguments(\n",
    "    output_dir=save_dir,               # Same output directory as during training\n",
    "    per_device_eval_batch_size=16,       # Evaluation batch size\n",
    ")\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=evaluation_args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test_dataset\n",
    "eval_result = eval_trainer.evaluate(test_dataset)\n",
    "\n",
    "# Print the evaluation result\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089778cf",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f904ef",
   "metadata": {},
   "source": [
    "* 기존의 __'klue/bert-base'__ 모델을 사용했을 땐, __1 epoch당 12시간__ 이 걸려서 도중에 포기하고 상대적으로 파라미터 수가 적고 모델이 가벼운 __'klue/roberta-small'__ 모델을 이용함. 해당 모델을 사용할 경우 __1 epoch당 약 4시간__ 가량 소요됨.\n",
    "\n",
    "* 데이터 개수를 줄이지 않고 __klue/roberta-small__ 모델을 사용해 __3epoch__ 학습 시, __accuracy 와 f1 score 모두 90 %__ 에 달함.\n",
    "\n",
    "* Bucketing Task는 시퀀스 길이가 비슷한 데이터끼리 뭉쳐서 적절한 최대 길이만큼 패딩을 진행한 후 학습하는 방식임. 패딩 토큰 양을 최소화함으로써 메모리를 효율적으로 사용할 수 있게 되어 학습 속도를 향상시키며 모델 성능 또한 개선시킬 수 있다고 함.\n",
    "\n",
    "* __Bucketing Task__ 를 실제로 돌려보았을 때 학습속도가 조금 개선됨. __3 에폭__ 돌릴 때 __약 7시간__ 정도 걸렸으나 __성능이 크게 개선되지는 않음.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3337d9",
   "metadata": {},
   "source": [
    "https://nkw011.github.io/nlp/tutorial4_Fine-tune_a_pretrained_model/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
